%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% ICML 2017 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the following line _only_ if you're still using LaTeX 2.09.
%\documentstyle[icml2017,epsf,natbib]{article}
% If you rely on Latex2e packages, like most moden people use this:
\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
\usepackage{subfigure} 

% For citations
\usepackage{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% for math operators
\usepackage{amsmath}
\DeclareMathOperator{\sign}{sign}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2017} with
% \usepackage[nohyperref]{icml2017} above.
\usepackage{hyperref}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% for code snippets:
\usepackage{xcolor}
\definecolor{codegray}{gray}{0.95}
\newcommand{\code}[1]{\colorbox{codegray}{\texttt{#1}}}


\newcommand{\foolbox}{Foolbox}
\newcommand{\x}{{\bf x}}
\newcommand{\g}{{\bf g}}


% use a mono-space font that's not as wide
\usepackage[T1]{fontenc}
\usepackage{inconsolata}

\usepackage{bbm}


% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
%\usepackage{icml2017} 

% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
%\usepackage[accepted]{icml2017}
\usepackage[accepted]{icml2017}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{AdvBox:A toolbox to take off the emperor’s new clothes of neural networks}

\begin{document} 

\twocolumn[
\icmltitle{AdvBox:A toolbox to take off the emperor’s new clothes of neural networks}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2017
% package.

% list of affiliations. the first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% you can specify symbols, otherwise they are numbered in order
% ideally, you should not use this facility. affiliations will be numbered
% in order of appearance and this is the preferred way.
%\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Dou Goodman}{baidu}
\icmlauthor{Hao Xin}{baidu}
\icmlauthor{Wang Yang}{baidu}
\end{icmlauthorlist}

% \icmlaffiliation{uni}{University of T\"ubingen, Germany}
\icmlaffiliation{baidu}{Baidu X-Lab}

\icmlcorrespondingauthor{Dou Goodman}{liu.yan@baidu.com}

% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{python, adversarial examples, robustness, neural networks, machine learning, adversarials, adversarial attacks}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\begin{NoHyper}
%printAffiliationsAndNotice{\icmlEqualContribution{}} % otherwise use the standard text.
\printAffiliationsAndNotice{} 
\end{NoHyper}


\begin{abstract} 

\cite{Szegedy2013Intriguing}. discovered an intriguing properties of deep neural networks in the context of image classification for the first time. They showed that despite the state-of-the-art deep networks are surprisingly susceptible to adversarial attacks in the form of small perturbations to images that remain (almost) imperceptible to human vision system. These perturbations are found by optimizing the input to maximize the prediction error and the images modified by these perturbations are called as adversarial examples. The profound implications of these results triggered a wide interest of researchers in adversarial attacks and their defenses for deep learning in general. Advbox is a toolbox to generate adversarial examples that fool neural networks in PaddlePaddle, PyTorch, Caffe2, MxNet, Keras, tensorFlow and Advbox can benchmark the robustness of machine learning models.  Advbox give a command line tool to generate adversarial examples with Zero-Coding.Code and examples available at \url{https://github.com/baidu/AdvBox},licensed
under the Apache License 2.0.

\end{abstract} 

\section{Adversarial Examples Overview}
\cite{Szegedy2013Intriguing} discovered an intriguing properties of deep neural networks in the context of image classification for the first time. They showed that despite the state-of-the-art deep networks are surprisingly susceptible to adversarial attacks in the form of small perturbations to images that remain (almost) imperceptible to human vision system. These perturbations are found by optimizing the input to maximize the prediction error and the images modified by these perturbations are called as adversarial examples. The profound implications of these results triggered a wide interest of researchers in adversarial attacks and their defenses for deep learning in general.The initially involved computer vision task is image classification. For that, a variety of attacking methods have been proposed, such as  FGSM of \cite{goodfellow2014explaining}, deepfool of \cite{Moosavidezfooli2016DeepFool} ,CW of \cite{Carlini2017Towards}  and so on. Transferability of adversarial examples was first examined by \cite{Szegedy2013Intriguing}, which studied the transferability between different models trained over the same dataset.The study of transferability was followed by \cite{goodfellow2014explaining}, which attributed the phe nomenon of transferability to the reason that the adversarial perturbation is highly aligned with the weight vector of the model. Again, this hypothesis was tested using MNIST and CIFAR-10 datasets. We show that this is not the case for models trained over ImageNet.\cite{Liu2016Delving} show that while existing approaches are effective to generate non-targeted transferable adversarial examples , only few targeted adversarial examples generated by existing methods can transfer .They propose novel ensemble-based approaches to generate adversarial examples . Their approaches enable a large portion of targeted adversarial examples to transfer among multiple models for the first time.\cite{wei2018transferable} propose the Unified and Efficient Adversary (UEA) for attacking image and video object detection. UEA is the first attacking method that can not only efficiently deal with both image and video data, but also simultaneously fool the proposal based detectors and regression based detectors.

\section{AdvBox Overview}
Advbox is a toolbox to generate adversarial examples that fool neural networks in PaddlePaddle,PyTorch,Caffe2,MxNet,Keras,TensorFlow and Advbox can benchmark the robustness of machine learning models.  Advbox give a command line tool to generate adversarial examples with Zero-Coding.Advbox improves upon the existing Python package cleverhans by \cite{Papernot2016cleverhans} in three important aspects:

\begin{enumerate}
    \item Advbox is a toolbox to generate adversarial examples that fool neural networks in PaddlePaddle,PyTorch,Caffe2,MxNet,Keras,TensorFlow and Advbox can benchmark the robustness of machine learning models. 
    \item Advbox give a command line tool to generate adversarial examples with Zero-Coding. 
    \item Advbox also support white-box and black-box attacks and defence algorithms.
\end{enumerate}

\subsection{advbox.attack}
Advbox implements several popular adversarial attacks which search adversarial examples. Each attack method uses a distance measure(L1, L2, etc.) to quantify the size of adversarial perturbations. Advbox is easy to craft adversarial example as some attack methods could perform internal hyperparameter tuning to find the minimum perturbation.

\subsection{advbox.model}
Advbox implements interfaces to PaddlePaddle. Additionally, other deep learning framworks such as TensorFlow can also be defined and employed. The module is use to compute predictions and gradients for given inputs in a specific framework.

\subsection{advbox.adversary}
Adversary contains the original object, the target and the adversarial examples. It provides the misclassification as the criterion to accept a adversarial example.

\section{Implemented A White-box attack methods}

\begin{itemize}
\item L-BFGS
\item FGSM
\item BIM
\item ILCM
\item MI-FGSM
\item JSMA
\item DeepFool
\item C/W
\end{itemize}

\section{Implemented A Black-box attack methods}

\begin{itemize}
\item Single Pixel Attack 
\item Local Search Attack
\end{itemize}

\section{Implemented A Defense methods}

\begin{itemize}
\item Feature Fqueezing 
\item Spatial Smoothing 
\item Label Smoothing 
\item Gaussian Augmentation 
\item Adversarial Training
\item Thermometer Encoding
\end{itemize}

\section{Implemented Attack AI application}
Attack Face recognition


\bibliography{paper}
\bibliographystyle{icml2017}


\end{document} 


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was
% created by Lise Getoor and Tobias Scheffer, it was slightly modified  
% from the 2010 version by Thorsten Joachims & Johannes Fuernkranz, 
% slightly modified from the 2009 version by Kiri Wagstaff and 
% Sam Roweis's 2008 version, which is slightly modified from 
% Prasad Tadepalli's 2007 version which is a lightly 
% changed version of the previous year's version by Andrew Moore, 
% which was in turn edited from those of Kristian Kersting and 
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.  
